#!/bin/bash

#SBATCH --partition=gpu_mig
#SBATCH --gpus=1
#SBATCH --job-name=RechunkZarrV2
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=8
#SBATCH --time=04:00:00
#SBATCH --output=cluster_workflow/jobs/slurm_outputs/rechunk_zarr_v2_%A.out
#SBATCH --error=cluster_workflow/jobs/slurm_outputs/rechunk_zarr_v2_%A.err

# Rechunk all datasets to Zarr v2 with optimized chunks for ML training
# Uses 8 timesteps per chunk for better random access performance

module purge
module load 2023
module load Anaconda3/2023.07-2

source activate aurora-highres
CODE_DIR="$HOME/aurora-highres"
DATA_DIR="/projects/prjs1858"

echo "=== RECHUNKING ZARR DATASETS (V2 OPTIMIZED) ==="
echo "CODE_DIR: $CODE_DIR"
echo "DATA_DIR: $DATA_DIR"
echo ""

cd $CODE_DIR
export PYTHONPATH=".";

# 1. Rechunk HRES dataset
echo "=== Rechunking HRES dataset ==="
python examples/rechunk_zarr_v2.py \
    --input "$DATA_DIR/hres_europe_2018_2020.zarr" \
    --output "$DATA_DIR/hres_europe_2018_2020_v2opt.zarr" \
    --time-chunk 8 \
    --compressor blosc \
    --overwrite

# 2. Rechunk latents dataset
echo ""
echo "=== Rechunking Latents dataset ==="
python examples/rechunk_zarr_v2.py \
    --input "$DATA_DIR/latents_europe_2018_2020.zarr" \
    --output "$DATA_DIR/latents_europe_2018_2020_v2opt.zarr" \
    --time-chunk 8 \
    --compressor blosc \
    --overwrite

# 3. Rechunk static dataset (no time dimension, just recompress)
echo ""
echo "=== Rechunking Static dataset ==="
python examples/rechunk_zarr_v2.py \
    --input "$DATA_DIR/static_hres_europe.zarr" \
    --output "$DATA_DIR/static_hres_europe_v2opt.zarr" \
    --time-chunk 1 \
    --compressor blosc \
    --overwrite

echo ""
echo "=== COMPLETE ==="
echo "Optimized datasets:"
echo "  - $DATA_DIR/hres_europe_2018_2020_v2opt.zarr"
echo "  - $DATA_DIR/latents_europe_2018_2020_v2opt.zarr"
echo "  - $DATA_DIR/static_hres_europe_v2opt.zarr"
echo ""
echo "Update your training config to use these paths!"
